{
  "hash": "f73c603af38c250acf8eacab6ad879d9",
  "result": {
    "markdown": "---\ntitle: \"Intro\"\nformat: html\n---\n\n\n***WORK IN PROGRESS***\n\n\n::: {.cell}\n\n```{.r .cell-code}\nknitr::opts_chunk$set(message=FALSE, warning=FALSE, error=FALSE)\n```\n:::\n\n\n# Overview\n\nThis module provides an introduction to concepts in cloud-native geospatial analyses through the lens of environmental justice.  \nThis module assumes familiarity with the R computing environment, ideally through the core concepts of reading, visualizing, and manipulating data as introduced in [R For Data Science](https://r4ds.hadley.nz/). \nWhile prior experience in geospatial tooling is not assumed, this module is not intended to be a complete tutorial on geospatial concepts -- please consider the text [Geocomputation with R](https://r.geocompx.org/) for a more thorough treatment.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(rstac)\nlibrary(gdalcubes)\nlibrary(stars)\nlibrary(tmap) # must be v4, install using remotes::install_github('r-tmap/tmap')\ngdalcubes::gdalcubes_options(parallel = TRUE)\n```\n:::\n\n\n\n# Spatial Vector Objects\n\nSpatial data objects come in essentially two flavors: **vector** and **raster** objects.  \nSpatial **vector** data can be thought of as a special case of a tabular data (or relational database) structure, consisting of rows and columns.  \nEach row represents a \"feature\" defined by explicit spatial coordinate type such as a point, line, or polygon, as indicated in a special \"geometry\" column.\nAdditionally, all spatial data objects (vectors or rasters) include core spatial metadata information, indicating the spatial projection \n\nWe read in geospatial vector data which uses polygons to represent each housing area assessed by the Home Owners Loan Corporation\n\n\n::: {.cell}\n\n```{.r .cell-code}\nCASanFrancisco1937 <- \"https://dsl.richmond.edu/panorama/redlining/static/downloads/geojson/CASanFrancisco1937.geojson\"\n\nredlines <- \n  paste0(\"/vsicurl/\", CASanFrancisco1937) |>\n  st_read() |> \n  st_make_valid() # fix mangled/incomplete polygons\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nReading layer `CASanFrancisco1937' from data source \n  `/vsicurl/https://dsl.richmond.edu/panorama/redlining/static/downloads/geojson/CASanFrancisco1937.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 97 features and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -122.5101 ymin: 37.70801 xmax: -122.3627 ymax: 37.80668\nGeodetic CRS:  WGS 84\n```\n:::\n:::\n\n\nNote how we add the prefix `/vsicurl/` in front of the URL.  Under the hood, nearly all of our spatial libraries call the [GDAL](https://gdal.org/user/virtual_file_systems.html) C library to do the heavy lifting of reading and working with the 100s of different file formats used to represent geospatial vector and raster data.  Using this prefix tells GDAL to use the \"[Virtual Filesystem](https://gdal.org/user/virtual_file_systems.html)\" rather than download the entire data object.\n\n\nWe can get a quick visualization of these polygons overlaid on an interactive (Javascript leaflet) map by setting the `tmap` mode to `\"view\"`. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Use a color scheme for grades based on HOLC maps\ncolors <-  tm_scale_categorical(values=c(A = \"#729765\",\n                                         B = \"#75a4b3\",\n                                         C = \"#c6c167\",\n                                         D = \"#b0707b\" ))\n\n\ntmap_mode(\"view\")\ntm_shape(redlines) + \n  tm_polygons(\"holc_grade\", fill.scale = colors, fill_alpha = 0.6)\n```\n:::\n\n\nWe can also make rich static plots with `tmap`, e.g. \n\n\n::: {.cell}\n\n```{.r .cell-code}\ntmap_mode(\"plot\")\n\n\n  tm_basemap(providers$CartoDB.Positron) + \n  tm_shape(redlines) + \n  tm_borders(col=\"holc_grade\", \n             lwd = 4, \n             col.scale = colors) +\n  tm_text(text = \"holc_grade\", size=0.5, col=\"holc_grade\") +\n  tm_legend_hide()\n```\n\n::: {.cell-output-display}\n![](r-intro_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n\n# Spatial Rasters\n\n\nSpatial rasters represent data on discrete regular grid cells (pixels). \nSatellite imagery is a common source of spatial raster data that quickly becomes very very large, making the cloud native approaches such as the virtual filesystem mentioned above quite essential.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## STAC Search over 400 million assets.\n\n# manual bounding box\n# box <-  c(xmin=-122.51006, ymin=37.70801, xmax=-122.36268, ymax=37.80668)\n# or just extract bounding box from city map:\nbox <- st_bbox(redlines)  \nstart_date <- \"2022-06-01\"\nend_date <- \"2022-08-01\"\nitems <- \n  stac(\"https://earth-search.aws.element84.com/v0/\") |>\n  stac_search(collections = \"sentinel-s2-l2a-cogs\",\n              bbox = c(box),\n              datetime = paste(start_date, end_date, sep=\"/\"),\n              limit = 100) |>\n  post_request() \n```\n:::\n\n\n## Low-level approach\n\nHere we manually explore some of the information returned by the STAC catalog ...\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 12 matching features\nlength(items$features)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 12\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nitems$features[[1]] |> names()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"type\"            \"stac_version\"    \"stac_extensions\" \"id\"             \n [5] \"bbox\"            \"geometry\"        \"properties\"      \"collection\"     \n [9] \"assets\"          \"links\"          \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nitems$features[[1]]$assets |> names()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"thumbnail\" \"overview\"  \"info\"      \"metadata\"  \"visual\"    \"B01\"      \n [7] \"B02\"       \"B03\"       \"B04\"       \"B05\"       \"B06\"       \"B07\"      \n[13] \"B08\"       \"B8A\"       \"B09\"       \"B11\"       \"B12\"       \"AOT\"      \n[19] \"WVP\"       \"SCL\"      \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nb04 <- items$features[[1]]$assets$B04 \nc(b04$title, b04$type)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Band 4 (red)\"                                            \n[2] \"image/tiff; application=geotiff; profile=cloud-optimized\"\n```\n:::\n:::\n\n\n\nManually assemble the visual red-green-blue bands\n\n\n::: {.cell}\n\n```{.r .cell-code}\ni <- 11\n\nblue <- paste0(\"/vsicurl/\", items$features[[i]]$assets$B02$href)\ngreen <- paste0(\"/vsicurl/\", items$features[[i]]$assets$B03$href)\nred <- paste0(\"/vsicurl/\", items$features[[i]]$assets$B04$href)\n\nvis <- read_stars(c(red,green,blue)) |> merge()\nplot(vis, rgb=1:3)\n```\n\n::: {.cell-output-display}\n![](r-intro_files/figure-html/stars_vis-1.png){width=672}\n:::\n:::\n\n\nNote that even seemingly simple tasks like cropping to a spatial subset require manual re-projection first, and this is relatively computationally intensive. This process will be much faster when we use the approach of `gdalcubes` instead.  \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Note this low-level interace won't automatically deal with CRS transformations, but throws:\n# Error in st_crop.stars_proxy(vis, redlines) :\n# for cropping, the CRS of both objects has to be identical\n\n# vis |> st_crop(redlines)\n\n# We must manually reproject, which is slow and resource intensive\n# We'll avoid this by using gdalcubes which allows the warper to handle this instead\n\n# vis_sf <- vis |> st_transform(st_crs(redlines)) |> st_crop(redlines)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Don't try this, will definitely crash!\n#ggplot() + geom_stars(data = vis) + scale_fill_identity()\n```\n:::\n\n\nWe can still do network-based\n\n\n::: {.cell}\n\n```{.r .cell-code}\nred <- read_stars(red)\nb08 <- paste0(\"/vsicurl/\", items$features[[i]]$assets$B08$href)\nnir <- read_stars(b08)\nndvi <- (nir - red) / (nir + red)\nplot(ndvi)\n```\n\n::: {.cell-output-display}\n![](r-intro_files/figure-html/stars_ndvi-1.png){width=672}\n:::\n:::\n\n\nThis approach does not mask clouds and fill or average over other images -- we've used only one of the matching assets so far. While a single image here covers our area of interest (AOI),  in an expanded spatial analysis we would need to tile together overlapping images to ensure we cover the full AOI.  This also operates at native resolution, which can hurt performance when scaling to larger AOI.\n\n\n\n## Newer cloud-native approach\n\nRather than manually parse the STAC catalog information, we can simply pass this metadata on to an intelligent function that knows how to use this.  We specify what bands of interest and request that any images where the metadata indicates over 20% cloud cover be dropped from the collection.  \n\n\n::: {.cell}\n\n```{.r .cell-code}\ncol <-\n  stac_image_collection(items$features,\n                        asset_names = c(\"B02\", \"B03\", \"B04\",\"B08\", \"SCL\"),\n                        property_filter = \\(x) {x[[\"eo:cloud_cover\"]] < 20})\n```\n:::\n\n\n\nSeperately, we define an abstract \"data cube\" indicating how we want our data to look -- the bounding box in space and time, and the spatial/temporal resolution we want for the data.  \n\n\n::: {.cell}\n\n```{.r .cell-code}\ncube <- cube_view(srs = \"EPSG:4326\",  \n                  extent = list(t0 = start_date, t1 = end_date,\n                                left = box[1], right = box[3],\n                                top = box[4], bottom = box[2]),\n                  nx = 2400, ny = 2400, dt = \"P1M\",\n                  aggregation = \"median\", resampling = \"average\")\n```\n:::\n\n\nThird, we create an image mask indicating which pixels should be removed by using the data quality control layer, which indicates pixels that post-processing had identified as corresponding to clouds or cloud shadows:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nS2.mask <- image_mask(\"SCL\", values=c(3,8,9)) # mask clouds and cloud shadows\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nraster_cube(col, cube, mask = S2.mask) |>\n  select_bands(c(\"B02\", \"B03\", \"B04\")) |>\n  aggregate_time(dt=\"P1M\") |>\n  plot(rgb=3:1)\n```\n\n::: {.cell-output-display}\n![](r-intro_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nndvi <- raster_cube(col, cube, mask = S2.mask) |>\n  select_bands(c(\"B04\", \"B08\")) |>\n  apply_pixel(\"(B08-B04)/(B08+B04)\", \"NDVI\") |>\n  reduce_time(c(\"mean(NDVI)\")) |>\n  st_as_stars()\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntm_shape(ndvi) + \n  tm_raster(col.scale = tm_scale_continuous(values = viridisLite::mako(30)))\n```\n\n::: {.cell-output-display}\n![](r-intro_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntm_shape(ndvi) + \n  tm_raster(col.scale = tm_scale_continuous(values = viridisLite::mako(30))) +\n  tm_shape(redlines) + tm_borders(col=\"holc_grade\", lwd = 4, \n                                  col.scale = tm_scale_categorical(values=c(\n                                    A = \"#729765\",\n                                    B = \"#75a4b3\",\n                                    C = \"#c6c167\",\n                                    D = \"#b0707b\" ))) +\n  tm_text(text = \"holc_grade\", size = 0.5, col = \"holc_grade\")\n```\n\n::: {.cell-output-display}\n![](r-intro_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# more scalable performance with gdalcubes::extract_geom\nndvi_aves <- raster_cube(col, cube, mask = S2.mask) |>\n  select_bands(c(\"B04\", \"B08\")) |>\n  apply_pixel(\"(B08-B04)/(B08+B04)\", \"NDVI\") |>\n  reduce_time(c(\"mean(NDVI)\")) |>\n  extract_geom(redlines, FUN=mean)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nave_ndvi <- redlines |> \n  rowid_to_column(\"FID\") |>\n  left_join(ndvi_aves) \n\nave_ndvi |>\n  as_tibble() |>\n  group_by(holc_grade) |>\n  summarise(mean = mean(NDVI_mean))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 4 × 2\n  holc_grade  mean\n  <chr>      <dbl>\n1 A          0.316\n2 B          0.212\n3 C          0.195\n4 D          0.194\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# \"standard method\"\n# aves <- stars::st_extract(ndvi, redlines, FUN=mean)\n\n# vec <- as_tibble(aves) |> left_join(redlines)\n#vec |> group_by(holc_grade) |>\n#   summarise(ndvi = mean(NDVI_mean, na.rm=TRUE))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntmap_mode(\"view\")\ntm_shape(ave_ndvi) + \n  tm_polygons(\"NDVI_mean\", \n              fill_alpha = 0.8,\n              fill.scale = tm_scale_continuous(values = \"Greens\")) +\n  tm_shape(redlines) + \n  tm_borders(col=\"holc_grade\", \n             lwd = 4, \n             col.scale = tm_scale_categorical(values=c(\n                A = \"#729765\",\n                B = \"#75a4b3\",\n                C = \"#c6c167\",\n                D = \"#b0707b\" ))) +\n  tm_text(text = \"holc_grade\", size = 0.5)\n```\n:::",
    "supporting": [
      "r-intro_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}